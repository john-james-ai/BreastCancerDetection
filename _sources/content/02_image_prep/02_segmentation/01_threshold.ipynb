{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c668a4b",
   "metadata": {},
   "source": [
    "# Threshold-Based Segmentation\n",
    "\n",
    "Our first step in the segmentation process is to separate the foreground of the mammogram containing the breast region of interest (ROI) from the background.  The result of this *binarization* process is a binary image or mask that can be used to isolate ROIs, label structures within the image, detect edges and contours, classify abnormalities, and perform other tasks across the image analysis workflow.\n",
    "\n",
    "This *binarization* of the image can be accomplished using a range of statistical approaches and sophisticated machine-learning classification methods that group pixels of an image into different classes. However, the simplest approach would be to set a pixel value cut-off point, or *threshold*, that separates groups of pixel intensities from each other. From a grayscale mammogram, a binary image or mask is created whereby all pixel values less than or equal to the threshold are set to 0 and all other pixel values are set to 1  [^binary].\n",
    "\n",
    "[^binary]: WLOG some software packages equivalently set pixel values above the threshold to 255, instead of 1. Converting between these representations can be achieved via normalization of the pixel values.\n",
    "\n",
    "Image binarization using pixel intensity thresholds is suitable in digital mammography where pixel intensity is the parameter that most directly relates to the spatial characteristics of the structures within a mammogram. Hence, binarization using threshold-based segmentation is often a critical first step in many biomedical image analysis workflows.\n",
    "\n",
    "The taxonomy of threshold-based segmentation techniques can be roughly characterized as global threshold segmentation and adaptive local threshold segmentation.\n",
    "\n",
    "## Global Threshold Segmentation\n",
    "\n",
    "Global threshold segmentation applies a single designated or automatically selected threshold value to the entire image.  Specifically, let $I$ be the input image with height $H$ and width $W$ pixels, and that $I_{x,y}$ represents the gray value of row $x$ and column $y$ of $I$, such that $0 \\le x < H, 0 \\le y < W$. Then, $B_{x,y}$ represents the binary value in row $x$ and column $y$ of binary mask $B$, and is given by:\n",
    "\n",
    "```{math}\n",
    ":label: global_threshold\n",
    "B_{x,y} = \\begin{cases}\n",
    "1 & if I_{x,y} > T \\\\\n",
    "0 & if I_{x,y} \\le T \\\\\n",
    "\\end{cases}\n",
    "```\n",
    "\n",
    "where $T$ is a global threshold.\n",
    "\n",
    "To illustrate, let’s create some binary masks for our test images using a manually set threshold $T=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ded03e",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../../../..\")))\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from myst_nb import glue\n",
    "\n",
    "from bcd.preprocess.image.threshold import (ThresholdAnalyzer,\n",
    "    ThresholdLi, ThresholdISOData, ThresholdTriangle, ThresholdOTSU, ThresholdAdaptiveMean, ThresholdAdaptiveGaussian, ThresholdManual\n",
    ")\n",
    "\n",
    "img1 = \"data/image/1_dev/converted/train/benign/347c2455-cb62-40f8-a173-9e4eb9a21902.png\"\n",
    "img2 = \"data/image/1_dev/converted/train/benign/4ed91643-1e06-4b2c-8efb-bc60dd9e0313.png\"\n",
    "img3 = \"data/image/1_dev/converted/train/malignant/7dcc12fd-88f0-4048-a6ab-5dd0bd836f08.png\"\n",
    "img4 = \"data/image/1_dev/converted/train/malignant/596ef5db-9610-4f13-9c1a-4c411b1d957c.png\"\n",
    "\n",
    "img1 = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2, cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread(img3, cv2.IMREAD_GRAYSCALE)\n",
    "img4 = cv2.imread(img4, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "images = (img1,img2,img3,img4)\n",
    "\n",
    "analyzer = ThresholdAnalyzer()\n",
    "threshold = ThresholdManual(threshold=10)\n",
    "fig = analyzer.analyze(images=images, threshold=threshold)\n",
    "\n",
    "glue(\"threshold_manual_10\", fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc0312",
   "metadata": {},
   "source": [
    "```{glue:figure} threshold_manual_10\n",
    "---\n",
    "align: center\n",
    "name: threshold_manual_10_fig\n",
    "---\n",
    "Manual Threshold-Based Segmentation with $T=10$\n",
    "```\n",
    "\n",
    "In {numref}`threshold_manual_10_fig`, we have our four randomly selected images, the associated binary masks, and the output images. At threshold $T=10$, we have a clear separation between foreground and background; however, we have little to no artifact suppression.\n",
    "\n",
    "Let’s examine the effect of increasing the threshold to $T=100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427077f",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "analyzer = ThresholdAnalyzer()\n",
    "threshold = ThresholdManual(threshold=100)\n",
    "fig = analyzer.analyze(images=images, threshold=threshold)\n",
    "\n",
    "glue(\"threshold_manual_100\", fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983ee9c",
   "metadata": {},
   "source": [
    "```{glue:figure} threshold_manual_100\n",
    "---\n",
    "align: center\n",
    "name: threshold_manual_100_fig\n",
    "---\n",
    "Manual Threshold-Based Segmentation with $T=100$\n",
    "```\n",
    "\n",
    "{numref}`threshold_manual_10_fig` and {numref}`threshold_manual_100_fig` illustrate the first key takeaway of this section.\n",
    "\n",
    "`````{admonition} In threshold segmentation, the choice of threshold is crucial!\n",
    ":class: tip\n",
    "Different thresholds may yield dramatically different segmentation results.\n",
    "`````\n",
    "\n",
    "A threshold that is too low tends to produce over-segmentation, combining distinct objects into single structures and failing to separate artifacts from regions of interest as shown in {numref}`threshold_manual_10_fig`  (i)-(l). On the other hand, a high threshold can make objects smaller, resulting in loss of information as structures of interest are designated to the background as evidenced in {numref}`threshold_manual_100_fig`  (i)-(l).\n",
    "\n",
    "So, what are the principled ways by which an appropriate threshold is selected? This leads to our second key takeaway.\n",
    "\n",
    "`````{admonition} Choosing a threshold manually should be avoided, when possible!\n",
    ":class: tip\n",
    "Manual thresholding is inefficient, irreproducible, and a huge source of user bias.\n",
    "`````\n",
    "\n",
    "...rant in 3,…2,…\n",
    "\n",
    "Selecting thresholds manually is tedious, time-consuming, and a huge source of user bias. It is based upon human perception of what information should be extracted from the image, leading to high intra- and inter-user variability; further compounded by the inherent variability in digital mammography. One fixed threshold will not extract similar features from different images. Manual thresholding has little to no reproducibility and it is incompatible with automatic, image-driven thresholding that is based on image-intrinsic properties and not on subjective real-time user decisions.\n",
    "\n",
    "So, what is the alternative?\n",
    "\n",
    "## Automated Thresholding\n",
    "\n",
    "Image processing literature is replete with automatic thresholding algorithms of various types, each based upon a vast array of image-intrinsic properties.  Automated thresholding has several benefits vis-à-vis manual thresholding.\n",
    "\n",
    "- **Bias-Free Thresholding**: No user bias is introduced during *thresholding*,\n",
    "- **Objectivity**: Thresholds are objectively determined and image-specific,\n",
    "- **Reproducibility**: They are reproducible, in that a parameterized algorithm will always produce the same binarization result for a given image,\n",
    "- **Efficient**: They are fast, computationally efficient, and easily automated in image analysis and preprocessing workflows.\n",
    "\n",
    "Notwithstanding, automated thresholding presents certain challenges for the practitioner.\n",
    "\n",
    "- **No Free Lunch**: {cite}`wolpertNoFreeLunch1997a`: There is no universally superior automated thresholding algorithm that performs equally well for all biomedical images, modalities, contexts, and needs.\n",
    "- **Algorithm Selection Bias**: Algorithm selection is a subjective user decision based upon experience, human perception, and prior expectations concerning the information to be extracted from an image. For instance, an algorithm selected by the current expert pathologist may eliminate a structure later determined to be a critical indicator.\n",
    "- **Prior Knowledge**: Practitioners may lack the domain expertise required to effectively characterize the performance of the algorithms under evaluation. Algorithm selection is often based upon a priori expectation of visual features, structures, and information to be extracted during the segmentation process.\n",
    "\n",
    "Selecting an appropriate automated thresholding algorithm from the growing space of candidate solutions is an increasingly challenging endeavor, guided by the intended use of the extracted information, the questions to be answered, the quality, format, and modality of the imaging content, and a working understanding of candidate algorithm performance characteristics.\n",
    "\n",
    "### Automated Thresholding Algorithm Space\n",
    "\n",
    "Sezgin and Sankur {cite}`sankurSurveyImageThresholding2004` cast the space of automated thresholding techniques as follows:\n",
    "\n",
    "- **Histogram shape-based methods** that analyze, for instance, the peaks, valleys, and curvatures of smoothed histograms.\n",
    "- **Clustering-based methods** cluster the gray-level samples into background and foreground. Alternatively, the image is modeled as a mixture of two Gaussians.\n",
    "- **Entropy-based methods** use the entropy of the foreground and background regions, the cross-entropy between the original and binarized image, etc.\n",
    "- **Object attribute-based methods** that analyze the similarity between the gray-level and the binarized images, such as fuzzy shape similarity, edge coincidence, etc.\n",
    "- **The spatial methods** use higher-order probability distribution and/or correlation between pixels\n",
    "- **Local methods** adapt the threshold value on each pixel to the local image characteristics.\n",
    "\n",
    "For the taxonomist, Sezgin’s framework is not mutually exclusive and collectively exhaustive (MECE). For instance, Otsu’s Method {cite}`otsuThresholdSelectionMethod1979` can be categorized as both a histogram shape-based method and a clustering-based method.\n",
    "\n",
    "### Automated Threshold Methods\n",
    "\n",
    "Our candidate space will be comprised of the following ({numref}`auto-thresh-tbl`) histogram-based, entropy-based, and local-based threshold methods.\n",
    "\n",
    "```{table} Automated Threshold Methods\n",
    ":name: auto-thresh-tbl\n",
    "\n",
    "\n",
    "| Type            | Method                               | Author(s)                                            | Publication                                                  |\n",
    "|-----------------|--------------------------------------|------------------------------------------------------|--------------------------------------------------------------|\n",
    "| Histogram-Based | Triangle Method                      | Zack, G. W., Rogers, W. E. and Latt, S. A., 1977,    | Automatic Measurement of Sister Chromatid Exchange Frequency |\n",
    "|                 | ISOData Method                       | Ridler, TW & Calvard, S (1978)                       | Picture thresholding using an iterative selection method     |\n",
    "|                 | Otsu's Method                        | Nobuyuki Otsu (1979)                                 | A threshold selection method from gray-level histograms      |\n",
    "| Entropy-Based   | Li's Minimum Cross Entropy Method    | Li C.H. and Lee C.K. (1993)                          | Minimum Cross Entropy Thresholding                           |\n",
    "| Spatial-Based   | Yen's Multilevel Thresholding Method | Jui-Cheng Yen, Fu-Juay Chang and Shyang Chang (1995) | A new criterion for automatic multilevel thresholding        |\n",
    "| Local           | Adaptive Gaussian Method             | Bradley, D., G. Roth 2007                            | Adapting Thresholding Using the Integral Image               |\n",
    "|                 | Adaptive Mean Method                 | Bradley, D., G. Roth 2007                            | Adapting Thresholding Using the Integral Image               |                                       |\n",
    "\n",
    "```\n",
    "\n",
    "In the remaining sections, we will describe how each method works, visualize the segmentation results, and characterize method assumptions, strengths, and limitations.\n",
    "\n",
    "#### Histogram-Based Thresholding\n",
    "\n",
    "Histogram-based methods use the distribution of pixel intensities to determine an appropriate threshold."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.1"
   }
  },
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   41,
   75,
   89,
   97
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}