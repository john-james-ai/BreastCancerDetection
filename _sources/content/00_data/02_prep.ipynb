{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880a8092",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "In the prior section, we identified a few structural concerns worth addressing before any quality or exploratory analysis analyses take place. Here, we extract the relevant task-specific information from the CBIS-DDSM case and dicom datasets and integrate the data into a single, combined full mammogram dataset.\n",
    "\n",
    "Our process will take four steps:\n",
    "1. Combine the calcification mass training and test sets into a single full mammogram dataset,\n",
    "2. Add DICOM image file paths to the *series* metadata,\n",
    "3. Extract the *DICOM* image metadata and merge it with the case data from #1.\n",
    "4. Create the Dataset object, our access to the CBIS-DDSM data.\n",
    "\n",
    "The full dataset will have a few upgrades that will facilitate the analysis, detection, and classification tasks:\n",
    "1. A mammogram ID, consisting of abnormality type, fileset (train/test), patient_id, breast laterality, and view will uniquely identify each full mammogram image.\n",
    "2. A Boolean target variable, 'cancer', will be added combining BENIGN and BENIGN_WITHOUT_CALLBACK into a single Boolean value.\n",
    "3. The Dataset will be a self-explanatory API for analysis, exploration, experimentation, and visualization.\n",
    "\n",
    "Alright.\n",
    "\n",
    "## Case Dataset Integration\n",
    "The following code cells will integrate all case data into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78272bad",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../../..\")))\n",
    "from typing import Union\n",
    "from glob import glob\n",
    "\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "\n",
    "from bcd.dal.file import IOService\n",
    "from bcd.utils.file import getsize\n",
    "from bcd.utils.profile import profiler\n",
    "from bcd.data_prep.base import DataPrep\n",
    "from bcd.data_prep.case import CasePrep\n",
    "from bcd.data_prep.series import SeriesPrep\n",
    "from bcd.data_prep.cbis import CBISPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2a98b",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 39-173 bcd/data_prep/case.py\n",
    "class CasePrep(DataPrep):\n",
    "    \"\"\"Performs Case metadata preparation.\n",
    "\n",
    "    Combines training and test cases into a single csv case file.\n",
    "\n",
    "    Args:\n",
    "        calc_train_fp, calc_test_fp, mass_train_fp, mass_test_fp (str): The file paths to the\n",
    "            calcification and mass training and test sets.\n",
    "        case_fp (str): Path to output calcification and mass datasets.\n",
    "        force (bool): Whether to force execution if output already exists. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        calc_train_fp: str,\n",
    "        calc_test_fp: str,\n",
    "        mass_train_fp: str,\n",
    "        mass_test_fp: str,\n",
    "        case_fp: str,\n",
    "        force: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._calc_train_fp = calc_train_fp\n",
    "        self._calc_test_fp = calc_test_fp\n",
    "        self._mass_train_fp = mass_train_fp\n",
    "        self._mass_test_fp = mass_test_fp\n",
    "        self._case_fp = case_fp\n",
    "        self._force = force\n",
    "\n",
    "    def prep(self) -> pd.DataFrame:\n",
    "        \"\"\"Combines training and test cases into a single csv case file.\"\"\"\n",
    "\n",
    "        if self._force or not os.path.exists(self._case_fp):\n",
    "            # Merge all case data into a single DataFrame\n",
    "            df_cases = self._merge_cases()\n",
    "\n",
    "            # Set morphological features to NA as appropriate\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"mass\", \"calc_type\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"mass\", \"calc_distribution\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"calcification\", \"mass_shape\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"calcification\", \"mass_margins\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "\n",
    "            # Assign the mammogram id.\n",
    "            df_cases = self._assign_mmg_id(df=df_cases)\n",
    "\n",
    "            # Create the Boolean target corresponding to pathology\n",
    "            df_cases[\"cancer\"] = np.where(\n",
    "                df_cases[\"pathology\"] == \"MALIGNANT\", True, False\n",
    "            )\n",
    "\n",
    "            # Drop the filename columns.\n",
    "            columns_to_drop = [\n",
    "                \"image_file_path\",\n",
    "                \"cropped_image_file_path\",\n",
    "                \"ROI_mask_file_path\",\n",
    "            ]\n",
    "            df_cases = df_cases.drop(columns=columns_to_drop)\n",
    "\n",
    "            # Change laterality to laterality, the DICOM attribute\n",
    "            df_cases = df_cases.rename(columns={\"laterality\": \"laterality\"})\n",
    "\n",
    "            self._save(df=df_cases, filepath=self._case_fp)\n",
    "\n",
    "            return df_cases\n",
    "\n",
    "        return pd.read_csv(self._case_fp)\n",
    "\n",
    "    def _merge_cases(self) -> pd.DataFrame:\n",
    "        \"\"\"Combines mass and calcification train and test files into a single file.\"\"\"\n",
    "        # Extracts absolute paths, a pre-emptive measure in case\n",
    "        # jupyter book can't access the path\n",
    "        calc_train_fp = os.path.abspath(self._calc_train_fp)\n",
    "        calc_test_fp = os.path.abspath(self._calc_test_fp)\n",
    "        mass_train_fp = os.path.abspath(self._mass_train_fp)\n",
    "        mass_test_fp = os.path.abspath(self._mass_test_fp)\n",
    "\n",
    "        # Read the data\n",
    "        df_calc_train = pd.read_csv(calc_train_fp)\n",
    "        df_calc_test = pd.read_csv(calc_test_fp)\n",
    "        df_mass_train = pd.read_csv(mass_train_fp)\n",
    "        df_mass_test = pd.read_csv(mass_test_fp)\n",
    "\n",
    "        # Add the filesets\n",
    "        df_calc_train[\"fileset\"] = \"training\"\n",
    "        df_calc_test[\"fileset\"] = \"test\"\n",
    "        df_mass_train[\"fileset\"] = \"training\"\n",
    "        df_mass_test[\"fileset\"] = \"test\"\n",
    "\n",
    "        # Standardize column names with underscores in place of spaces.\n",
    "        df_calc_train = self._format_column_names(df=df_calc_train)\n",
    "        df_calc_test = self._format_column_names(df=df_calc_test)\n",
    "        df_mass_train = self._format_column_names(df=df_mass_train)\n",
    "        df_mass_test = self._format_column_names(df=df_mass_test)\n",
    "\n",
    "        # Concatenate the files\n",
    "        df = pd.concat(\n",
    "            [df_calc_train, df_calc_test, df_mass_train, df_mass_test], axis=0\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _assign_mmg_id(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Assign a mammogram id to each observation.\"\"\"\n",
    "        df[\"mmg_id\"] = (\n",
    "            df[\"abnormality_type\"].apply(lambda x: x[0:4].capitalize())\n",
    "            + \"-\"\n",
    "            + df[\"fileset\"].apply(lambda x: x.capitalize())\n",
    "            + \"_\"\n",
    "            + df[\"patient_id\"]\n",
    "            + \"_\"\n",
    "            + df[\"laterality\"].apply(lambda x: x.upper())\n",
    "            + \"_\"\n",
    "            + df[\"image_view\"].apply(lambda x: x.upper())\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _format_column_names(self, df: pd.DataFrame) -> str:\n",
    "        \"\"\"Replaces spaces in column names with underscores.\"\"\"\n",
    "\n",
    "        def replace_columns(colname: str) -> str:\n",
    "            return colname.replace(\" \", \"_\")\n",
    "\n",
    "        df.columns = df.columns.to_series().apply(replace_columns)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39340660",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_test = \"data/meta/0_raw/calc_case_description_test_set.csv\"\n",
    "calc_train = \"data/meta/0_raw/calc_case_description_train_set.csv\"\n",
    "mass_test = \"data/meta/0_raw/mass_case_description_test_set.csv\"\n",
    "mass_train = \"data/meta/0_raw/mass_case_description_train_set.csv\"\n",
    "\n",
    "case_fp = \"data/meta/1_interim/cases.csv\"\n",
    "\n",
    "cp = CasePrep(calc_train_fp=calc_train, calc_test_fp=calc_test, mass_train_fp=mass_train, mass_test_fp=mass_test, case_fp=case_fp, force=False)\n",
    "cases = cp.prep()\n",
    "cases.info()\n",
    "cases.sample(n=5, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbaf6af",
   "metadata": {},
   "source": [
    "The dataset above has both mass and calcification training and test data, as well as a mammogram id, 'mmmg_id', and a Boolean target 'cancer'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b1565",
   "metadata": {},
   "source": [
    "## Series Metadata\n",
    "Next, we add filepaths to the series metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 31-88 bcd/data_prep/series.py\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class SeriesPrep(DataPrep):\n",
    "    \"\"\"Adds filepaths to the Series dataset\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the DICOM series metadata.\n",
    "        series_filepath (str) Path for the results\n",
    "        force (bool): Whether to force execution if output already exists. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    __BASEDIR = \"data/image/0_raw/\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        series_filepath: str,\n",
    "        force: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._filepath = os.path.abspath(filepath)\n",
    "        self._series_filepath = os.path.abspath(series_filepath)\n",
    "        self._force = force\n",
    "\n",
    "    @profiler\n",
    "    def prep(self) -> pd.DataFrame:\n",
    "        \"\"\"Extracts image metadata from the DICOM image files.\"\"\"\n",
    "\n",
    "        if self._force or not os.path.exists(self._series_filepath):\n",
    "            # Reads the series metadata that contains subject, series, and\n",
    "            # file location information\n",
    "            studies = IOService.read(self._filepath)\n",
    "\n",
    "            # Add filepaths to the study data first to avoid batch\n",
    "            # operation exceptions with dask.\n",
    "            studies = self._get_filepaths(studies=studies)\n",
    "\n",
    "            df = pd.DataFrame(data=studies)\n",
    "\n",
    "            self._save(df=df, filepath=self._series_filepath)\n",
    "\n",
    "            return df\n",
    "\n",
    "        return pd.read_csv(self._series_filepath)\n",
    "\n",
    "    def _get_filepaths(self, studies: pd.Series) -> pd.DataFrame:\n",
    "        \"\"\"Adds filepaths to the studies dataframe\"\"\"\n",
    "        studies_filepaths = []\n",
    "        for _, row in studies.iterrows():\n",
    "            location = row[\"file_location\"].replace(\"./\", \"\")\n",
    "            filepath = os.path.join(self.__BASEDIR, location)\n",
    "            filepaths = glob(filepath + \"/*.dcm\")\n",
    "            for file in filepaths:\n",
    "                row[\"filepath\"] = file\n",
    "                studies_filepaths.append(row)\n",
    "        return studies_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpi = \"data/meta/0_raw/metadata.csv\"\n",
    "fpo = \"data/meta/3_final/series.csv\"\n",
    "sp = SeriesPrep(filepath=fpi, series_filepath=fpo, force=False)\n",
    "series = sp.prep()\n",
    "series.info()\n",
    "series.sample(n=5, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f933b9",
   "metadata": {},
   "source": [
    "Full filepaths have been added for all 10,239 images in the CBIS-DDSM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a0d46",
   "metadata": {},
   "source": [
    "## DICOM Image Metadata\n",
    "\n",
    "Next, we extract the DICOM data described in {numref}`dicom_image_metadata` and merge that with the case data.\n",
    "\n",
    "```{table} DICOM Image Metadata\n",
    ":name: dicom_image_metadata\n",
    "\n",
    "| # | Name                       | Description                                                                              |\n",
    "|---|----------------------------|------------------------------------------------------------------------------------------|\n",
    "| 1 | bit_depth                  | Number of bits used to define each pixel                                                 |\n",
    "| 2 | rows                       | Number of pixel rows in the image                                                        |\n",
    "| 3 | cols                       | Number of pixel columns in the image                                                     |\n",
    "| 4 | aspect_ratio               | Ratio of width to height in image                                                        |\n",
    "| 5 | size                       | Product of width and height in image                                                     |\n",
    "| 6 | min_pixel_value            | Minimum pixel value                                                                      |\n",
    "| 7 | max_pixel_value            | Maximum pixel value                                                                      |\n",
    "| 8 | mean_pixel_value           | Average pixel value                                                                      |\n",
    "| 9 | std_pixel_value            | Standard deviation of pixel values                                                       |\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96c0fa",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 35-143 bcd/data_prep/cbis.py\n",
    "class CBISPrep(DataPrep):\n",
    "    \"\"\"Extracts DICOM data and integrates it with a single Case dataset staged for quality assessment.\n",
    "\n",
    "    Iterates through the full mammography DICOM metadata in parallel, extracting image and pixel\n",
    "    data and statistics, then combines the data with the case dataset.\n",
    "\n",
    "    Args:\n",
    "        case_filepath (str): Path to the case dataset.\n",
    "        series_filepath (str): Path to the series dataset.\n",
    "        cbis_filepath (str): Path to the combined case dicom dataset.\n",
    "        force (bool): Whether to force execution if output already exists. Default is False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        case_filepath: str,\n",
    "        series_filepath: str,\n",
    "        cbis_filepath: str,\n",
    "        force: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self._case_filepath = os.path.abspath(case_filepath)\n",
    "        self._series_filepath = os.path.abspath(series_filepath)\n",
    "        self._cbis_filepath = os.path.abspath(cbis_filepath)\n",
    "        self._force = force\n",
    "\n",
    "    @profiler\n",
    "    def prep(self) -> pd.DataFrame:\n",
    "        \"\"\"Extracts image metadata from the DICOM image files.\"\"\"\n",
    "\n",
    "        if self._force or not os.path.exists(self._cbis_filepath):\n",
    "            # Reads the series metadata that contains subject, series, and\n",
    "            # file location information\n",
    "            cases = IOService.read(self._case_filepath)\n",
    "            series = IOService.read(self._series_filepath)\n",
    "\n",
    "            # Obtain the full mammogram images\n",
    "            series = series.loc[series[\"series_description\"] == \"full mammogram images\"]\n",
    "\n",
    "            results = []\n",
    "            # Graph of work is created and executed lazily at compute time.\n",
    "            for _, study in series.iterrows():\n",
    "                image_result = dask.delayed(self._extract_data)(study)\n",
    "                results.append(image_result)\n",
    "\n",
    "            # Compute the results and convert to dataframe\n",
    "            results = dask.compute(*results)\n",
    "            df = pd.DataFrame(data=results)\n",
    "\n",
    "            # Merge the data with the case dataset\n",
    "            df = cases.merge(df, on=\"mmg_id\", how=\"inner\")\n",
    "\n",
    "            self._save(df=df, filepath=self._cbis_filepath)\n",
    "\n",
    "            return df\n",
    "\n",
    "        return IOService.read(self._cbis_filepath)\n",
    "\n",
    "    def _extract_data(self, study: pd.Series) -> dict:\n",
    "        \"\"\"Reads study and dicom data from a file.\"\"\"\n",
    "\n",
    "        dcm = pydicom.dcmread(study[\"filepath\"])\n",
    "        img = dcm.pixel_array\n",
    "\n",
    "        d = {}\n",
    "        d[\"mmg_id\"] = \"_\".join(study[\"subject_id\"].split(\"_\")[0:5])\n",
    "        d[\"bit_depth\"] = dcm.BitsStored\n",
    "        d[\"rows\"], d[\"cols\"] = img.shape\n",
    "        d[\"aspect_ratio\"] = d[\"cols\"] / d[\"rows\"]\n",
    "        d[\"size\"] = d[\"rows\"] * d[\"cols\"]\n",
    "        d[\"file_size\"] = getsize(study[\"filepath\"])\n",
    "        d[\"min_pixel_value\"] = dcm.SmallestImagePixelValue\n",
    "        d[\"max_pixel_value\"] = dcm.LargestImagePixelValue\n",
    "        d[\"mean_pixel_value\"] = np.mean(img)\n",
    "        d[\"std_pixel_value\"] = np.std(img)\n",
    "        d[\"filepath\"] = study[\"filepath\"]\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdc88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = \"data/meta/1_interim/cases.csv\"\n",
    "series = \"data/meta/3_final/series.csv\"\n",
    "cbis = \"data/meta/2_staged/cbis.csv\"\n",
    "cp = CBISPrep(case_filepath=cases, series_filepath=series, cbis_filepath=cbis, force=False)\n",
    "cbis = cp.prep()\n",
    "cbis.info()\n",
    "cbis.sample(n=5, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfffe6",
   "metadata": {},
   "source": [
    "We have all case information along with the DICOM image metadata in a single dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fb9ba6",
   "metadata": {},
   "source": [
    "Finally, we integrate the data into a Dataset for quality assessment and exploratory data analysis."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.0"
   }
  },
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   34,
   57,
   197,
   210,
   214,
   219,
   278,
   285,
   289,
   312,
   396,
   404,
   408
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}