{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d10891",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "Our final data preparation task before exploratory data analysis is to prepare a dataset for multivariate analysis.   For multivariate modeling, we will be one-hot encoding the morphological features and normalizing numeric data to values in [0,1]. \n",
    "\n",
    "The multivariate analysis will include 12 independent variables: breast_density, laterality, image_view, abnormality_id, abnormality_type,  calc_type, calc_distribution, subtlety, mass_shape, mass_margins, mean_pixel_value, and std_pixel_value. The binary dependent target variable will be cancer. Variables not included in the analysis are pathology and assessment, since both of these variables are essentially proxies for the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e56546f",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../../..\")))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bcd.data_prep.transform import CBISTransformer\n",
    "pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab19a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_CBIS = \"data/meta/3_clean/cbis.csv\"\n",
    "FP_CBIS_MODELING_DATA = \"data/meta/3_clean/cbis_model_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e1ba71",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 34-178 bcd/data_prep/transform.py\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "#                                   CBIS TRANSFORMER                                               #\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "MODEL_VARS = [\n",
    "    \"breast_density\",\n",
    "    \"laterality\",\n",
    "    \"image_view\",\n",
    "    \"abnormality_id\",\n",
    "    \"abnormality_type\",\n",
    "    \"calc_type\",\n",
    "    \"calc_distribution\",\n",
    "    \"subtlety\",\n",
    "    \"mass_shape\",\n",
    "    \"mass_margins\",\n",
    "    \"cancer\",\n",
    "    \"mean_pixel_value\",\n",
    "    \"std_pixel_value\",\n",
    "]\n",
    "CALC_TYPES = [\n",
    "    \"AMORPHOUS\",\n",
    "    \"COARSE\",\n",
    "    \"DYSTROPHIC\",\n",
    "    \"EGGSHELL\",\n",
    "    \"FINE_LINEAR_BRANCHING\",\n",
    "    \"LARGE_RODLIKE\",\n",
    "    \"LUCENT_CENTERED\",\n",
    "    \"MILK_OF_CALCIUM\",\n",
    "    \"PLEOMORPHIC\",\n",
    "    \"PUNCTATE\",\n",
    "    \"ROUND_AND_REGULAR\",\n",
    "    \"SKIN\",\n",
    "    \"VASCULAR\",\n",
    "]\n",
    "CALC_DISTRIBUTIONS = [\n",
    "    \"CLUSTERED\",\n",
    "    \"LINEAR\",\n",
    "    \"REGIONAL\",\n",
    "    \"DIFFUSELY_SCATTERED\",\n",
    "    \"SEGMENTAL\",\n",
    "]\n",
    "MASS_SHAPES = [\n",
    "    \"IRREGULAR\",\n",
    "    \"ARCHITECTURAL_DISTORTION\",\n",
    "    \"OVAL\",\n",
    "    \"LYMPH_NODE\",\n",
    "    \"LOBULATED\",\n",
    "    \"FOCAL_ASYMMETRIC_DENSITY\",\n",
    "    \"ROUND\",\n",
    "    \"ASYMMETRIC_BREAST_TISSUE\",\n",
    "]\n",
    "MASS_MARGINS = [\n",
    "    \"SPICULATED\",\n",
    "    \"ILL_DEFINED\",\n",
    "    \"CIRCUMSCRIBED\",\n",
    "    \"OBSCURED\",\n",
    "    \"MICROLOBULATED\",\n",
    "]\n",
    "\n",
    "ENC_VARS = {\n",
    "    \"abnormality_type\": {\"prefix\": \"AT\", \"values\": [\"calcification\", \"mass\"]},\n",
    "    \"laterality\": {\"prefix\": \"LR\", \"values\": [\"LEFT\", \"RIGHT\"]},\n",
    "    \"image_view\": {\"prefix\": \"IV\", \"values\": [\"CC\", \"MLO\"]},\n",
    "    \"calc_type\": {\"prefix\": \"CT\", \"values\": CALC_TYPES},\n",
    "    \"calc_distribution\": {\"prefix\": \"CD\", \"values\": CALC_DISTRIBUTIONS},\n",
    "    \"mass_shape\": {\"prefix\": \"MS\", \"values\": MASS_SHAPES},\n",
    "    \"mass_margins\": {\"prefix\": \"MM\", \"values\": MASS_MARGINS},\n",
    "}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class CBISTransformer:\n",
    "    \"\"\"Collapses morphological categories and dummy encodes nominal variables.\n",
    "\n",
    "    The CBIS-DDSM has 45 calcification types, 9 calcification distributions, 20 mass shapes, and\n",
    "    19 mass margins, many of which are compound categories, in that two or more categories are\n",
    "    combined. For instance, calcification type 'ROUND_AND_REGULAR-PUNCTATE-AMORPHOUS' indicates\n",
    "    three different types: 'ROUND_AND_REGULAR', 'PUNCTATE', and 'AMORPHOUS'. Segregating these\n",
    "    compound categories into separate categories will drastically reduce the number of categories\n",
    "    to analyze. More importantly, it aligns our data and the analyses with the common morphological\n",
    "    taxonomy. So, task one is to extract the unary morphological categories from the\n",
    "    compound classifications.\n",
    "\n",
    "    Args:\n",
    "        source_fp (str): Path to source file\n",
    "        destination_fp (str): Path to destination file\n",
    "        force (bool): Whether to force execution if the destination file already exists.\n",
    "            Default = False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, source_fp: str, destination_fp: str, force: bool = False\n",
    "    ) -> None:\n",
    "        self._source_fp = os.path.abspath(source_fp)\n",
    "        self._destination_fp = os.path.abspath(destination_fp)\n",
    "        self._force = force\n",
    "        self._logger = logging.getLogger(f\"{self.__class__.__name__}\")\n",
    "        self._logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    def transform(self) -> pd.DataFrame:\n",
    "        \"\"\"Performs the transformation of the data.\"\"\"\n",
    "        if not os.path.exists(self._destination_fp) or self._force:\n",
    "            df = pd.read_csv(self._source_fp)\n",
    "            # Excluding identify variables\n",
    "            df_model_vars = df[MODEL_VARS].copy()\n",
    "            df_model_vars[\"cancer\"] = np.where(\n",
    "                df_model_vars[\"cancer\"] == True, 1, 0\n",
    "            )  # noqa\n",
    "\n",
    "            # One-hot encode variables\n",
    "            df_enc = self._encode_dataset(df=df_model_vars)\n",
    "            # Dropping original string variables.\n",
    "            df_numeric = df_enc.select_dtypes(exclude=[\"object\"])\n",
    "            # Normalize all values to [0,1]\n",
    "            df_norm = self._normalize(df=df_numeric)\n",
    "            self._save(df=df_norm)\n",
    "            return df_norm\n",
    "        else:\n",
    "            return pd.read_csv(self._destination_fp)\n",
    "\n",
    "    def _encode_dataset(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"One-hot encodes the dataset\"\"\"\n",
    "        for feature, data in ENC_VARS.items():\n",
    "            for value in data[\"values\"]:\n",
    "                df = self._encode_column(\n",
    "                    df=df, prefix=data[\"prefix\"], col=feature, value=value\n",
    "                )\n",
    "        return df\n",
    "\n",
    "    def _encode_column(self, df, prefix, col, value):\n",
    "        \"One-hot encodes column\"\n",
    "        newcol = prefix + \"_\" + value\n",
    "        df[newcol] = np.where(df[col].str.contains(value), 1, 0)\n",
    "        return df\n",
    "\n",
    "    def _normalize(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Normalizes all values to [0,1]\"\"\"\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col] / (df[col].abs().max() - df[col].abs().min())\n",
    "        return df\n",
    "\n",
    "    def _save(self, df: pd.DataFrame) -> None:\n",
    "        os.makedirs(os.path.dirname(self._destination_fp), exist_ok=True)\n",
    "        df.to_csv(self._destination_fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d478847",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x4mr \u001b[38;5;241m=\u001b[39m \u001b[43mCBISTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFP_CBIS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFP_CBIS_MODELING_DATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m x4mr\u001b[38;5;241m.\u001b[39mtransform()\n",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m, in \u001b[0;36mCBISTransformer.__init__\u001b[0;34m(self, source_fp, destination_fp, force)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_destination_fp \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(destination_fp)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force \u001b[38;5;241m=\u001b[39m force\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger \u001b[38;5;241m=\u001b[39m \u001b[43mlogging\u001b[49m\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "x4mr = CBISTransformer(source_fp=FP_CBIS, destination_fp=FP_CBIS_MODELING_DATA, force=False)\n",
    "df = x4mr.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7d5fec",
   "metadata": {},
   "source": [
    "Ok, let's check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aaea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafd1b3",
   "metadata": {},
   "source": [
    "We have 43 variables, 37 of which are one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c513d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=5, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f525e",
   "metadata": {},
   "source": [
    "All values have been normalized and this dataset is ready for modeling. This completes the data transformation section. On to exploratory data analysis...finally!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.0"
   }
  },
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "source_map": [
   12,
   20,
   34,
   39,
   188,
   191,
   195,
   197,
   201,
   203
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}