{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from bcd.model.factory import ModelFactoryV1\n",
    "from bcd.model.experiment import Experiment\n",
    "from bcd.model.repo import ModelRepo\n",
    "pd.set_option('display.max_rows',999)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"01_model_V1.ipynb\"\n",
    "project = \"BCD_V1\"\n",
    "full_dataset = False\n",
    "\n",
    "# Model Parameters\n",
    "force = False  # Whether to retrain if the model and weights already exist from a prior training session.\n",
    "metrics = ['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "loss = \"binary_crossentropy\"\n",
    "activation = \"sigmoid\"\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "num_classes = 2\n",
    "\n",
    "# Dataset params\n",
    "dataset = \"CBIS-DDSM\" if full_dataset else \"CBIS-DDSM-10\"\n",
    "batch_size = 64 if full_dataset else 32\n",
    "input_shape = (224,224,3)\n",
    "output_shape = 1\n",
    "train_dir = pathlib.Path(\"data/image/1_final/training/training/\").with_suffix('') if full_dataset else pathlib.Path(\"data/image/1_final/training_10/training/\").with_suffix('') \n",
    "test_dir = pathlib.Path(\"data/image/1_final/test/test/\").with_suffix('')\n",
    "\n",
    "# Early stop parameters \n",
    "es_min_delta = 0.0001\n",
    "es_monitor = \"val_loss\"  # Monitor validation loss for early stopping\n",
    "es_patience = 8  # The number of epochs for which lack of improvement is tolerated \n",
    "es_restore_best_weights = True  # Returns the best weights rather than the weights at the last epoch.\n",
    "es_verbose = 1\n",
    "\n",
    "# Reduce LR on Plateau Parameters\n",
    "rlr_monitor = \"val_loss\"\n",
    "rlr_factor = 0.5\n",
    "rlr_patience = 3\n",
    "rlr_verbose = 1\n",
    "rlr_mode = \"auto\"\n",
    "rlr_min_delta = 1e-4\n",
    "rlr_min_lr=1e-10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project\": project,        \n",
    "    \"dataset\": dataset,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,    \n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"loss\": loss,    \n",
    "    \"early_stop_min_delta\": es_min_delta,\n",
    "    \"early_stop_monitor\": es_monitor,\n",
    "    \"early_stop_patience\": es_patience,\n",
    "    \"early_stop_restore_best_weights\": es_restore_best_weights,\n",
    "    \"early_stop_verbose\": es_verbose,\n",
    "    \"rlr_monitor\": rlr_monitor,\n",
    "    \"rlr_factor\": rlr_factor,\n",
    "    \"rlr_patience\": rlr_patience,\n",
    "    \"rlr_verbose\": rlr_verbose,\n",
    "    \"rlr_mode\": rlr_mode,\n",
    "    \"rlr_min_delta\": rlr_min_delta,\n",
    "    \"rlr_min_lr\": rlr_min_lr\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DataSet (10%)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation=\"bilinear\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Validation DataSet (10%)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    interpolation=\"bilinear\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Test Set\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor=es_monitor, \n",
    "                                                       min_delta=es_min_delta,\n",
    "                                                       patience=es_patience, \n",
    "                                                       restore_best_weights=es_restore_best_weights,\n",
    "                                                       verbose=es_verbose)\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=rlr_monitor,\n",
    "                                                          factor=rlr_factor,\n",
    "                                                          patience=rlr_patience,\n",
    "                                                          verbose=rlr_verbose,\n",
    "                                                          mode=rlr_mode,\n",
    "                                                          min_delta=rlr_min_delta,\n",
    "                                                          min_lr=rlr_min_lr)\n",
    "callbacks = [early_stop_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "repo = ModelRepo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the DenseNet model\n",
    "factory = ModelFactoryV1(input_shape=input_shape, output_shape=output_shape, activation=activation)\n",
    "densenet = factory.create_densenet()\n",
    "densenet.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "densenet_experiment = Experiment(model=densenet, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "densenet_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "densenet_experiment.classification_report(data=val_ds)\n",
    "densenet_experiment.plot_confusion_matrix(data=val_ds)\n",
    "densenet_experiment.evaluate(data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the ResNet model\n",
    "resnet = factory.create_resnet()\n",
    "resnet.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "resnet_experiment = Experiment(model=resnet, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "resnet_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "resnet_experiment.classification_report(data=val_ds)\n",
    "resnet_experiment.plot_confusion_matrix(data=val_ds)\n",
    "resnet_experiment.evaluate(data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the ResNet model\n",
    "inception = factory.create_inception()\n",
    "inception.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "inception_experiment = Experiment(model=inception, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "inception_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "inception_experiment.classification_report(data=val_ds)\n",
    "inception_experiment.plot_confusion_matrix(data=val_ds)\n",
    "inception_experiment.evaluate(data=test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Efficientnet model\n",
    "efficientnet = factory.create_efficientnet()\n",
    "efficientnet.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "efficientnet_experiment = Experiment(model=efficientnet, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "efficientnet_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "efficientnet_experiment.classification_report(data=val_ds)\n",
    "efficientnet_experiment.plot_confusion_matrix(data=val_ds)\n",
    "efficientnet_experiment.evaluate(data=test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception/Resnet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Inception_resnet model\n",
    "inception_resnet = factory.create_inception_resnet()\n",
    "inception_resnet.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "inception_resnet_experiment = Experiment(model=inception_resnet, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "inception_resnet_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "inception_resnet_experiment.classification_report(data=val_ds)\n",
    "inception_resnet_experiment.plot_confusion_matrix(data=val_ds)\n",
    "inception_resnet_experiment.evaluate(data=test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Mobilenet model\n",
    "mobilenet = factory.create_mobilenet()\n",
    "mobilenet.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "mobilenet_experiment = Experiment(model=mobilenet, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "mobilenet_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "mobilenet_experiment.classification_report(data=val_ds)\n",
    "mobilenet_experiment.plot_confusion_matrix(data=val_ds)\n",
    "mobilenet_experiment.evaluate(data=test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Xception model\n",
    "xception = factory.create_xception()\n",
    "xception.summary()\n",
    "\n",
    "# Create and run the experiment.\n",
    "xception_experiment = Experiment(model=xception, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "xception_experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "xception_experiment.classification_report(data=val_ds)\n",
    "xception_experiment.plot_confusion_matrix(data=val_ds)\n",
    "xception_experiment.evaluate(data=test_ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
