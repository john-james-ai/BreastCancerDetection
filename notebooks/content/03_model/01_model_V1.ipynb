{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "\n",
    "from bcd.model.factory import ModelFactoryV1\n",
    "from bcd.model.experiment import Experiment\n",
    "from bcd.model.repo import ModelRepo\n",
    "pd.set_option('display.max_rows',999)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Parameters\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"01_model_V1.ipynb\"\n",
    "full_dataset = False\n",
    "project = \"BCD_V1_CBIS-DDSM\" if full_dataset else \"BCD_V1_CBIS-DDSM-10\" \n",
    "\n",
    "# Model Parameters\n",
    "force = True  # Whether to retrain if the model and weights already exist from a prior training session.\n",
    "metrics = ['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "loss = \"binary_crossentropy\"\n",
    "activation = \"sigmoid\"\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "num_classes = 2\n",
    "\n",
    "# Dataset params\n",
    "dataset = \"CBIS-DDSM\" if full_dataset else \"CBIS-DDSM-10\"\n",
    "batch_size = 64 if full_dataset else 32\n",
    "input_shape = (224,224,3)\n",
    "output_shape = 1\n",
    "train_dir = pathlib.Path(\"data/image/1_final/training/training/\").with_suffix('') if full_dataset else pathlib.Path(\"data/image/1_final/training_10/training/\").with_suffix('') \n",
    "\n",
    "# Early stop parameters \n",
    "es_min_delta = 0.0001\n",
    "es_monitor = \"val_loss\"  # Monitor validation loss for early stopping\n",
    "es_patience = 10  # The number of epochs for which lack of improvement is tolerated \n",
    "es_restore_best_weights = True  # Returns the best weights rather than the weights at the last epoch.\n",
    "es_verbose = 1\n",
    "\n",
    "# Reduce LR on Plateau Parameters\n",
    "rlr_monitor = \"val_loss\"\n",
    "rlr_factor = 0.5\n",
    "rlr_patience = 3\n",
    "rlr_verbose = 1\n",
    "rlr_mode = \"auto\"\n",
    "rlr_min_delta = 1e-4\n",
    "rlr_min_lr=1e-10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project\": project,        \n",
    "    \"dataset\": dataset,\n",
    "    \"run_name\": None,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,    \n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"loss\": loss,    \n",
    "    \"early_stop_min_delta\": es_min_delta,\n",
    "    \"early_stop_monitor\": es_monitor,\n",
    "    \"early_stop_patience\": es_patience,\n",
    "    \"early_stop_restore_best_weights\": es_restore_best_weights,\n",
    "    \"early_stop_verbose\": es_verbose,\n",
    "    \"rlr_monitor\": rlr_monitor,\n",
    "    \"rlr_factor\": rlr_factor,\n",
    "    \"rlr_patience\": rlr_patience,\n",
    "    \"rlr_verbose\": rlr_verbose,\n",
    "    \"rlr_mode\": rlr_mode,\n",
    "    \"rlr_min_delta\": rlr_min_delta,\n",
    "    \"rlr_min_lr\": rlr_min_lr\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DataSet (10%)\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation=\"bilinear\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Validation DataSet (10%)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    interpolation=\"bilinear\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = ModelFactoryV1(input_shape=input_shape, output_shape=output_shape, activation=activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor=es_monitor, \n",
    "                                                       min_delta=es_min_delta,\n",
    "                                                       patience=es_patience, \n",
    "                                                       restore_best_weights=es_restore_best_weights,\n",
    "                                                       verbose=es_verbose)\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=rlr_monitor,\n",
    "                                                          factor=rlr_factor,\n",
    "                                                          patience=rlr_patience,\n",
    "                                                          verbose=rlr_verbose,\n",
    "                                                          mode=rlr_mode,\n",
    "                                                          min_delta=rlr_min_delta,\n",
    "                                                          min_lr=rlr_min_lr)\n",
    "callbacks = [early_stop_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "repo = ModelRepo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Runner\n",
    "Function to run an experiment for a named model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(name: str, config: dict) -> None:\n",
    "    # Get the Model\n",
    "    print(f\"\\n---------------------------Experiment: {name}---------------------------\\n\")\n",
    "    model = factory.create_model(name=name)\n",
    "    model.summary()    \n",
    "\n",
    "    # Create and run the experiment.\n",
    "    config[\"run_name\"] = name\n",
    "    experiment = Experiment(model=model, config=config, repo=repo, optimizer=optimizer, callbacks=callbacks, metrics=metrics, force=force)\n",
    "    experiment.run(train_ds=train_ds, val_ds=val_ds)\n",
    "    experiment.classification_report(data=val_ds)\n",
    "    experiment.plot_confusion_matrix(data=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"DenseNet\", \"EfficientNet\", \"Inception\", \"InceptionResNet\", \"MobileNet\", \"ResNet\", \"VGG\", \"Xception\"]\n",
    "for experiment in experiments:\n",
    "    run_experiment(name=experiment, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
