{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBIS-DDSM Data Preparation\n",
    "In the prior section, we obtained the CBIS-DDSM data from [The Cancer Imaging Archive](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=22516629) (TCIA). This brief section aims to convert the data to a form suitable for exploratory data analyses.  Once complete, we'll have the following four datasets for subsequent phase analysis:\n",
    "\n",
    "| # | Dataset              | Description                                                        |\n",
    "|---|----------------------|--------------------------------------------------------------------|\n",
    "| 1 | calc_cases.csv       | Calcification cases from the training and test sets.               |\n",
    "| 2 | mass_cases.csv       | Mass cases from the training and test sets.                        |\n",
    "| 3 | case_series_xref.csv | Case / Series Cross-Reference                                      |\n",
    "| 4 | dicom.csv            | DICOM dataset containing properties, and quality assessments for each image. |\n",
    "\n",
    "First, we'll build the case datasets (1,2,3), then we'll construct the DICOM image metadata and quality assessment dataset (4). \n",
    ", four datasets will be produced \n",
    "This Our tasks are as follows:\n",
    "\n",
    "5. **Assess Image Quality**: \n",
    "6. **Extract DICOM Image Metadata**: Extract image metadata such as height, width, bit-depth, pixel values, and photometric interpretation from DICOM image files.\n",
    "\n",
    "Once complete, we will have the following datasets for analysis:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "\n",
    "import pandas as  pd\n",
    "\n",
    "from bcd.data.prep.meta.case import CasePrep\n",
    "from bcd.data.prep.meta.dicom import DicomPrep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Case Datasets\n",
    "The data are currently split into train and test sets by BI-RADS category. While convenient for modeling, this is rather cumbersome for the exploratory data analysis which considers the entire dataset, before making any assumptions. Our first task is to combine the train and test sets into separate datasets by BI-RADS category, facilitating a top-down, comprehensive view of all the data during analysis. \n",
    "\n",
    "The target variable, pathology, has three values: 'MALIGNANT', 'BENIGN', and 'BENIGN_WITHOUT_CALLBACK. The latter indicates that some aspect of the case as worth tracking; but, no follow-up is required. For our purposes, that is a distinction without a difference. Nonetheless, rather than modifying the variable and lose potentially useful information, we'll create a new target variable, 'cancer', which will be True if pathology is 'MALIGNANT', and False otherwise. \n",
    "\n",
    "The CBIS-DDSM creators define a case as a particular abnormality as seen in the cranial caudal (CC) or mediolateral oblique (MLO) views; yet, the dataset lacks a unique case identifier. Consequently, five different variables are required to map metadata with their associated image. To enable direct matching between metadata and DICOM images, each case will be assigned a unique identifier, which will be cross-referenced to a full mammogram, ROI mask, or cropped image series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Input file paths\n",
    "CALC_TRAIN_FP = \"data/raw/meta/calc_train.csv\"\n",
    "CALC_TEST_FP = \"data/raw/meta/calc_test.csv\"\n",
    "\n",
    "MASS_TRAIN_FP = \"data/raw/meta/mass_train.csv\"\n",
    "MASS_TEST_FP = \"data/raw/meta/mass_test.csv\"\n",
    "\n",
    "# Output Filepaths\n",
    "CALC_FP = \"data/staged/calc_cases.csv\"\n",
    "MASS_FP = \"data/staged/mass_cases.csv\"\n",
    "CASE_SERIES_XREF__FP = \"data/staged/case_series_xref.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/john/projects/bcd/data/raw/meta/calc_case_description_train_set.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/john/projects/bcd/notebooks/content/02_data_prep.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/john/projects/bcd/notebooks/content/02_data_prep.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m case \u001b[39m=\u001b[39m CasePrep()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/john/projects/bcd/notebooks/content/02_data_prep.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dfc, dfm \u001b[39m=\u001b[39m case\u001b[39m.\u001b[39;49mprep(calc_train_fp\u001b[39m=\u001b[39;49mCALC_TRAIN_FP, calc_test_fp\u001b[39m=\u001b[39;49mCALC_TEST_FP, mass_train_fp\u001b[39m=\u001b[39;49mMASS_TRAIN_FP, mass_test_fp\u001b[39m=\u001b[39;49mMASS_TEST_FP, calc_fp\u001b[39m=\u001b[39;49mCALC_FP, mass_fp\u001b[39m=\u001b[39;49mMASS_FP, case_series_fp\u001b[39m=\u001b[39;49mCASE_SERIES_XREF__FP, result\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, force\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/john/projects/bcd/notebooks/content/02_data_prep.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Calcification Dataset has been created with \u001b[39m\u001b[39m{\u001b[39;00mdfc\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m rows and \u001b[39m\u001b[39m{\u001b[39;00mdfc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m columns.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/john/projects/bcd/notebooks/content/02_data_prep.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Mass Dataset has been created with \u001b[39m\u001b[39m{\u001b[39;00mdfm\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m rows and \u001b[39m\u001b[39m{\u001b[39;00mdfm\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m columns.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/bcd/bcd/data/prep/meta/case.py:76\u001b[0m, in \u001b[0;36mCasePrep.prep\u001b[0;34m(self, calc_train_fp, calc_test_fp, mass_train_fp, mass_test_fp, calc_fp, mass_fp, case_series_fp, force, result)\u001b[0m\n\u001b[1;32m     72\u001b[0m os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(case_series_fp), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m force \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(calc_fp):\n\u001b[1;32m     75\u001b[0m     \u001b[39m# Merge all case data into a single DataFrame\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     df_cases \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_cases(\n\u001b[1;32m     77\u001b[0m         calc_train_fp\u001b[39m=\u001b[39;49mcalc_train_fp,\n\u001b[1;32m     78\u001b[0m         calc_test_fp\u001b[39m=\u001b[39;49mcalc_test_fp,\n\u001b[1;32m     79\u001b[0m         mass_train_fp\u001b[39m=\u001b[39;49mmass_train_fp,\n\u001b[1;32m     80\u001b[0m         mass_test_fp\u001b[39m=\u001b[39;49mmass_test_fp,\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     83\u001b[0m     df_cases \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_case_id(df\u001b[39m=\u001b[39mdf_cases)\n\u001b[1;32m     85\u001b[0m     \u001b[39m# Transform 'BENIGN WITHOUT CALLBACK' to 'BENIGN'\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/bcd/bcd/data/prep/meta/case.py:118\u001b[0m, in \u001b[0;36mCasePrep._merge_cases\u001b[0;34m(self, calc_train_fp, calc_test_fp, mass_train_fp, mass_test_fp)\u001b[0m\n\u001b[1;32m    115\u001b[0m mass_train_fp \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(mass_train_fp)\n\u001b[1;32m    116\u001b[0m mass_test_fp \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(mass_test_fp)\n\u001b[0;32m--> 118\u001b[0m df_calc_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(calc_train_fp)\n\u001b[1;32m    119\u001b[0m df_calc_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(calc_test_fp)\n\u001b[1;32m    120\u001b[0m df_mass_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(mass_train_fp)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/john/projects/bcd/data/raw/meta/calc_case_description_train_set.csv'"
     ]
    }
   ],
   "source": [
    "case = CasePrep()\n",
    "dfc, dfm = case.prep(calc_train_fp=CALC_TRAIN_FP, calc_test_fp=CALC_TEST_FP, mass_train_fp=MASS_TRAIN_FP, mass_test_fp=MASS_TEST_FP, calc_fp=CALC_FP, mass_fp=MASS_FP, case_series_fp=CASE_SERIES_XREF__FP, result=True, force=False)\n",
    "print(f\"The Calcification Dataset has been created with {dfc.shape[0]} rows and {dfc.shape[1]} columns.\")\n",
    "print(f\"The Mass Dataset has been created with {dfm.shape[0]} rows and {dfm.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DICOM Dataset\n",
    "Developing an image preprocessing approach requires visibility into image metadata, currently buried in individual DICOM files. Our first task is to extract these data and store them in a format with greater accessibility. Note: There are 10,239 images in the dataset according to [TCIA](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=22516629#2251662935562334b1e043a3a0512554ef512cad). The DICOM image file for case_id 'P_01382_LEFT_mass_MLO_1' was corrupt, and could not be read. Therefore, we will have a total of 10,238 images.\n",
    "\n",
    "The performance of deep learning (DL) classification, detection, and diagnostic models and architectures depends on the quality of the data used in training. In this regard, we need an objective method, based on computational models, that can predict a radiologist's perception of the quality of an image. For this task, we will use the Blind/Reference-less Image Spatial Quality Evaluator (BRISQUE) algorithm. A widely used, state-of-the-art No-Reference Image Quality Assessment (NR-IQA) model, BRISQUE measures image quality using locally normalized luminance coefficients and image features. \n",
    "\n",
    "The DicomPrep class below will extract the DICOM data and assign a BRISQUE score to each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = \"data/raw/CBIS-DDSM\"\n",
    "DICOM_FP = \"data/staged/dicom.csv\"\n",
    "SKIP_LIST = [\"Mass-Training_P_01382_LEFT_MLO/07-20-2016-DDSM-93921/1.000000-full mammogram images-05891/1-1.dcm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom = DicomPrep()\n",
    "dfd = dicom.prep(location=LOCATION, dicom_fp=DICOM_FP, skip_list=SKIP_LIST, result=True, force=False)\n",
    "dfd = dicom.add_series_description(dicom_fp=DICOM_FP, series_fp=CASE_SERIES_XREF__FP)\n",
    "print(f\"The Calcification Dataset has been created with {dfd.shape[0]} rows and {dfd.shape[1]} columns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
