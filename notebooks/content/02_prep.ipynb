{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1: Structural Upgrade\n",
    "\n",
    "In the prior section, we identified a few structural concerns worth addressing before any quality or exploratory analysis efforts take place. Here, we apply a few upgrades that should streamline the data quality analysis in terms of structural consistency. \n",
    "\n",
    "The upgrades will involve the creation of two new datasets:\n",
    "\n",
    "```{table} Pre-Analysis Case and DICOM Datasets\n",
    "| # | Dataset                      | Description                                                                         |\n",
    "|---|------------------------------|-------------------------------------------------------------------------------------|\n",
    "| 1 | Case Dataset                 | Master case dataset with training and test data for calcification and mass cases. |\n",
    "| 2 | DICOM Image Metadata Dataset | Inventory of every image with reference back to the individual case.                |\n",
    "```\n",
    "First up? The case dataset.\n",
    "\n",
    "## Case Dataset Upgrades\n",
    "1.\tClean up the inconsistency in the variable names,\n",
    "2.\tCombine the training and test sets for masses and calcifications into a single master case file. Provide views for morphology or abnormality type-specific analysis.\n",
    "3.\tAdd `mmg_id`, a identifier for each mammogram comprised of <abnormality_type>-<fileset>_<patient_id>_<left_or_right_breast>_<image_view>. \n",
    "4.\tAdd a Boolean ‘cancer’ target variable that is True if the case is Malignant, False otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../../..\")))\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bcd.data_prep.base import DataPrep\n",
    "from bcd.data_prep.case import CasePrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load -r 38-179 bcd/data_prep/case.py\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class CasePrep(DataPrep):\n",
    "    \"\"\"Performs Case metadata preparation.\"\"\"\n",
    "\n",
    "    def prep(\n",
    "        self,\n",
    "        calc_train_fp: str,\n",
    "        calc_test_fp: str,\n",
    "        mass_train_fp: str,\n",
    "        mass_test_fp: str,\n",
    "        case_fp: str,\n",
    "        force: bool = False,\n",
    "        result: bool = False,\n",
    "    ) -> Union[None, pd.DataFrame]:\n",
    "        \"\"\"Combines training and test cases into a single csv case file.\n",
    "\n",
    "        Args:\n",
    "            calc_train_fp, calc_test_fp, mass_train_fp, mass_test_fp (str): The file paths to the\n",
    "                calcification and mass training and test sets.\n",
    "            case_fp (str): Path to output calcification and mass datasets.\n",
    "\n",
    "            force (bool): Whether to force execution if output already exists. Default is False.\n",
    "            result (bool): Whether the result should be returned. Default is False.\n",
    "\n",
    "        Returns\n",
    "            If result is True, the case dataframe is returned.\n",
    "        \"\"\"\n",
    "        case_fp = os.path.abspath(case_fp)\n",
    "\n",
    "        os.makedirs(os.path.dirname(case_fp), exist_ok=True)\n",
    "\n",
    "        if force or not os.path.exists(case_fp):\n",
    "            # Merge all case data into a single DataFrame\n",
    "            df_cases = self._merge_cases(\n",
    "                calc_train_fp=calc_train_fp,\n",
    "                calc_test_fp=calc_test_fp,\n",
    "                mass_train_fp=mass_train_fp,\n",
    "                mass_test_fp=mass_test_fp,\n",
    "            )\n",
    "\n",
    "            # Set morphological features to NA as appropriate\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"mass\", \"calc_type\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"mass\", \"calc_distribution\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"calcification\", \"mass_shape\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "            df_cases.loc[\n",
    "                df_cases[\"abnormality_type\"] == \"calcification\", \"mass_margins\"\n",
    "            ] = \"NOT APPLICABLE\"\n",
    "\n",
    "            # Assign the mammogram id.\n",
    "            df_cases = self._assign_mmg_id(df=df_cases)\n",
    "\n",
    "            # Transform 'BENIGN WITHOUT CALLBACK' to 'BENIGN'\n",
    "            df_cases[\"cancer\"] = np.where(\n",
    "                df_cases[\"pathology\"] == \"MALIGNANT\", True, False\n",
    "            )\n",
    "\n",
    "            # Drop the filename columns.\n",
    "            columns_to_drop = [\n",
    "                \"image_file_path\",\n",
    "                \"cropped_image_file_path\",\n",
    "                \"ROI_mask_file_path\",\n",
    "            ]\n",
    "            df_cases = df_cases.drop(columns=columns_to_drop)\n",
    "\n",
    "            # Save datasets\n",
    "            df_cases.to_csv(case_fp, index=False)\n",
    "\n",
    "        if result:\n",
    "            return pd.read_csv(case_fp)\n",
    "\n",
    "    def _merge_cases(\n",
    "        self,\n",
    "        calc_train_fp: str,\n",
    "        calc_test_fp: str,\n",
    "        mass_train_fp: str,\n",
    "        mass_test_fp: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Combines mass and calcification train and test files into a single file.\"\"\"\n",
    "        # Extracts absolute paths, a pre-emptive measure in case\n",
    "        # jupyter book can't access the path\n",
    "        calc_train_fp = os.path.abspath(calc_train_fp)\n",
    "        calc_test_fp = os.path.abspath(calc_test_fp)\n",
    "        mass_train_fp = os.path.abspath(mass_train_fp)\n",
    "        mass_test_fp = os.path.abspath(mass_test_fp)\n",
    "\n",
    "        df_calc_train = pd.read_csv(calc_train_fp)\n",
    "        df_calc_test = pd.read_csv(calc_test_fp)\n",
    "        df_mass_train = pd.read_csv(mass_train_fp)\n",
    "        df_mass_test = pd.read_csv(mass_test_fp)\n",
    "\n",
    "        # Add the filesets so that we can distinguish training\n",
    "        # and test data\n",
    "        df_calc_train[\"fileset\"] = \"training\"\n",
    "        df_calc_test[\"fileset\"] = \"test\"\n",
    "        df_mass_train[\"fileset\"] = \"training\"\n",
    "        df_mass_test[\"fileset\"] = \"test\"\n",
    "\n",
    "        # Replace spaces in column names with underscores.\n",
    "        df_calc_train = self._format_column_names(df=df_calc_train)\n",
    "        df_calc_test = self._format_column_names(df=df_calc_test)\n",
    "        df_mass_train = self._format_column_names(df=df_mass_train)\n",
    "        df_mass_test = self._format_column_names(df=df_mass_test)\n",
    "\n",
    "        # Concatenate the files\n",
    "        df = pd.concat(\n",
    "            [df_calc_train, df_calc_test, df_mass_train, df_mass_test], axis=0\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _assign_mmg_id(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Assign a mammogram id to each observation.\"\"\"\n",
    "        df[\"mmg_id\"] = (\n",
    "            df[\"abnormality_type\"].apply(lambda x: x[0:4].capitalize())\n",
    "            + \"-\"\n",
    "            + df[\"fileset\"].apply(lambda x: x.capitalize())\n",
    "            + \"_\"\n",
    "            + df[\"patient_id\"]\n",
    "            + \"_\"\n",
    "            + df[\"left_or_right_breast\"].apply(lambda x: x.upper())\n",
    "            + \"_\"\n",
    "            + df[\"image_view\"].apply(lambda x: x.upper())\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _format_column_names(self, df: pd.DataFrame) -> str:\n",
    "        \"\"\"Replaces spaces in column names with underscores.\"\"\"\n",
    "\n",
    "        def replace_columns(colname: str) -> str:\n",
    "            return colname.replace(\" \", \"_\")\n",
    "\n",
    "        df.columns = df.columns.to_series().apply(replace_columns)\n",
    "        return df\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m case_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/meta/1_interim/cases_staged.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m cp \u001b[38;5;241m=\u001b[39m CasePrep()\n\u001b[0;32m----> 7\u001b[0m cases \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_train_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_test_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalc_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmass_train_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmass_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmass_test_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmass_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m cases\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m      9\u001b[0m cases\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m55\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m, in \u001b[0;36mCasePrep.prep\u001b[0;34m(self, calc_train_fp, calc_test_fp, mass_train_fp, mass_test_fp, case_fp, force, result)\u001b[0m\n\u001b[1;32m     31\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(case_fp), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(case_fp):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Merge all case data into a single DataFrame\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     df_cases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_cases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalc_train_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalc_train_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcalc_test_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalc_test_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmass_train_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmass_train_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmass_test_fp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmass_test_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Set morphological features to NA as appropriate\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     df_cases\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m     44\u001b[0m         df_cases[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabnormality_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalc_type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT APPLICABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[2], line 112\u001b[0m, in \u001b[0;36mCasePrep._merge_cases\u001b[0;34m(self, calc_train_fp, calc_test_fp, mass_train_fp, mass_test_fp)\u001b[0m\n\u001b[1;32m    109\u001b[0m df_mass_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_column_names(df\u001b[38;5;241m=\u001b[39mdf_mass_test)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Concatenate the files\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_calc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_calc_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_mass_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_mass_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/pandas/core/reshape/concat.py:539\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    536\u001b[0m         keys \u001b[38;5;241m=\u001b[39m Index(clean_keys, name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll objects passed were None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objs_list, keys\n",
      "\u001b[0;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "calc_test = \"data/meta/0_raw/calc_case_description_test_set.csv\"\n",
    "calc_train = \"data/meta/0_raw/calc_case_description_train_set.csv\"\n",
    "mass_test = \"data/meta/0_raw/mass_case_description_test_set.csv\"\n",
    "mass_train = \"data/meta/0_raw/mass_case_description_train_set.csv\"\n",
    "case_fp = \"data/meta/1_interim/cases_staged.csv\"\n",
    "cp = CasePrep()\n",
    "cases = cp.prep(calc_train_fp=calc_train, calc_test_fp=calc_test, mass_train_fp=mass_train, mass_test_fp=mass_test, case_fp=case_fp, force=True, result=True)\n",
    "cases.info()\n",
    "cases.sample(n=5, random_state=55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICOM Image Metadata\n",
    "\n",
    "Here, our objective is to extract and augment the DICOM Image metadata from the DICOM files, producing the following dataset. \n",
    "\n",
    "```{table} DICOM Image Metadata\n",
    ":name: dicom_image_metadata\n",
    "| #  | Variable           | Source    | Description                                                                                                                                                                               |\n",
    "|----|--------------------|-----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| 1  | subject_id         | extracted | Identifier consisting of   <abnormality_type>-<fileset>_<patient_id>_<left_or_right_breast>_<image_view>[_abnormality_id].   Abnormality id is optional, used for ROI and cropped images. |\n",
    "| 2  | series_description | extracted | Describes whether the series if full mammogram, ROI, or cropped images.                                                                                                                   |\n",
    "| 3  | rows               | extracted | Number of rows in pixel array                                                                                                                                                             |\n",
    "| 4  | columns            | extracted | Number of columns in pixel array                                                                                                                                                          |\n",
    "| 5  | bits               | extracted | Bit resolution                                                                                                                                                                            |\n",
    "| 6  | image_id           | generated | Image identifier composed of the subject_id and an optional image number for ROI and cropped images.                                                                                    |\n",
    "| 7  | file_path           | generated | Path to the file on disk                                                                                                                                                                  |\n",
    "| 8  | file_size          | generated | File size                                                                                                                                                                                 |\n",
    "| 9  | size               | generated | Number of elements in pixel array                                                                                                                                                         |\n",
    "| 10 | min_pixel_value    | generated | Minimum pixel value                                                                                                                                                                       |\n",
    "| 11 | max_pixel_value    | generated | Maximum pixel value                                                                                                                                                                       |\n",
    "| 12 | mean_pixel_value   | generated | Average pixel value                                                                                                                                                                       |\n",
    "| 13 | std_pixel_value    | generated | Standard deviation of pixel values.                                                                                                                                                       |\n",
    "| 14 | mmg_id             | generated | Foreign mammogram identifier linking to cases.                                                                                                                                            |\n",
    "``\n",
    "As {numref}`dicom_image_metadata` shows, subject, series, and basic pixel data are extracted from the DICOM datasets.  We generate the image identifier, the mammogram identifier, the file path, the file size, the array size, as well as descriptive statistics on the image pixels. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
