{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from bcd.utils.image import convert_uint8\n",
    "from bcd.utils.visual import plot_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = \"data/image/1_dev/converted/train/benign/347c2455-cb62-40f8-a173-9e4eb9a21902.png\"\n",
    "img2 = \"data/image/1_dev/converted/train/benign/4ed91643-1e06-4b2c-8efb-bc60dd9e0313.png\"\n",
    "img3 = \"data/image/1_dev/converted/train/malignant/7dcc12fd-88f0-4048-a6ab-5dd0bd836f08.png\"\n",
    "img4 = \"data/image/1_dev/converted/train/malignant/596ef5db-9610-4f13-9c1a-4c411b1d957c.png\"\n",
    "img_filepaths = [img1, img2, img3, img4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2, cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread(img3, cv2.IMREAD_GRAYSCALE)\n",
    "img4 = cv2.imread(img4, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m images \u001b[38;5;241m=\u001b[39m [img1,img2,img3,img4]\n\u001b[1;32m      2\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplot_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/bcd/bcd/utils/visual.py:82\u001b[0m, in \u001b[0;36mplot_images\u001b[0;34m(images, nrows, titles, title, fontsize_ax_title, fontsize_fig_title, fontsize_label, show_ticks, show)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Ensure that number of images is an integer multiple of the number of rows.\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     83\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of images must be an integer multiple of the number of columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     logging\u001b[38;5;241m.\u001b[39mexception(msg)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "images = [img1,img2,img3,img4]\n",
    "title = \"Original Images\"\n",
    "plot_images(images=images, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_dn = cv2.medianBlur(img1, 3)\n",
    "img2_dn = cv2.medianBlur(img2, 3)\n",
    "img3_dn = cv2.medianBlur(img3, 3)\n",
    "img4_dn = cv2.medianBlur(img4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img1_dn,img2_dn,img3_dn,img4_dn]\n",
    "title = \"Denoised Images\"\n",
    "plot_images(images, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTSU Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, img1_otsu = cv2.threshold(img1_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, img2_otsu = cv2.threshold(img2_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, img3_otsu = cv2.threshold(img3_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, img4_otsu = cv2.threshold(img4_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_contours = cv2.findContours(img1_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "img2_contours = cv2.findContours(img2_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "img3_contours = cv2.findContours(img3_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "img4_contours = cv2.findContours(img4_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Contour Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_contour_areas = [cv2.contourArea(cont) for cont in img1_contours]\n",
    "img2_contour_areas = [cv2.contourArea(cont) for cont in img2_contours]\n",
    "img3_contour_areas = [cv2.contourArea(cont) for cont in img3_contours]\n",
    "img4_contour_areas = [cv2.contourArea(cont) for cont in img4_contours]\n",
    "\n",
    "img1_idx = np.argmax(img1_contour_areas)\n",
    "img2_idx = np.argmax(img2_contour_areas)\n",
    "img3_idx = np.argmax(img3_contour_areas)\n",
    "img4_idx = np.argmax(img4_contour_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_mask = cv2.drawContours(np.zeros_like(img1_otsu), img1_contours, img1_idx, 255, -1)\n",
    "img2_mask = cv2.drawContours(np.zeros_like(img2_otsu), img2_contours, img2_idx, 255, -1)\n",
    "img3_mask = cv2.drawContours(np.zeros_like(img3_otsu), img3_contours, img3_idx, 255, -1)\n",
    "img4_mask = cv2.drawContours(np.zeros_like(img4_otsu), img4_contours, img4_idx, 255, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment the Breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_seg = cv2.bitwise_and(img1, img1, mask=img1_mask)\n",
    "img2_seg = cv2.bitwise_and(img2, img2, mask=img2_mask)\n",
    "img3_seg = cv2.bitwise_and(img3, img3, mask=img3_mask)\n",
    "img4_seg = cv2.bitwise_and(img4, img4, mask=img4_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop the Breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, contours):\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    return img[y:y+h, x:x+w]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_crop = crop(img1_seg, img1_contours)\n",
    "img2_crop = crop(img2_seg, img2_contours)\n",
    "img3_crop = crop(img3_seg, img3_contours)\n",
    "img4_crop = crop(img4_seg, img4_contours)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhance Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_norm(img):\n",
    "    Pmin = np.percentile(img[img!=0], 5)\n",
    "    Pmax = np.percentile(img[img!=0], 99)\n",
    "    clipped = np.clip(img,Pmin, Pmax)  \n",
    "    normalized = (clipped - Pmin)/(Pmax - Pmin)\n",
    "    normalized[img==0]=0\n",
    "    return normalized    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img1_enhanced = clahe.apply(img1_crop)\n",
    "img2_enhanced = clahe.apply(img2_crop)\n",
    "img3_enhanced = clahe.apply(img3_crop)\n",
    "img4_enhanced = clahe.apply(img4_crop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
