{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from bcd.utils.image import convert_uint8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = \"data/image/2_exp/train/benign/2a44122c-f831-4220-95a8-408bcafcf2ce.png\"\n",
    "img2 = \"data/image/2_exp/train/malignant/19b64d16-ec08-4a99-9786-325a064108ff.png\"\n",
    "img3 = \"data/image/2_exp/train/benign/97556037-b959-4395-830b-380dcac2d58e.png\"\n",
    "img4 = \"data/image/2_exp/train/malignant/6cdf46d8-596b-47ab-a428-c8769733c93c.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(img2, cv2.IMREAD_GRAYSCALE)\n",
    "img3 = cv2.imread(img3, cv2.IMREAD_GRAYSCALE)\n",
    "img4 = cv2.imread(img4, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img1 = convert_uint8(img1)\n",
    "img2 = convert_uint8(img2)\n",
    "img3 = convert_uint8(img3)\n",
    "img4 = convert_uint8(img4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_dn = cv2.medianBlur(img1, 3)\n",
    "img2_dn = cv2.medianBlur(img2, 3)\n",
    "img3_dn = cv2.medianBlur(img3, 3)\n",
    "img4_dn = cv2.medianBlur(img4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTSU Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, img1_otsu = cv2.threshold(img1_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, img2_otsu = cv2.threshold(img2_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, img3_otsu = cv2.threshold(img3_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "_, img4_otsu = cv2.threshold(img4_dn, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_contours = cv2.findContours(img1_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "img2_contours = cv2.findContours(img2_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "img3_contours = cv2.findContours(img3_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "img4_contours = cv2.findContours(img4_otsu.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Contour Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_contour_areas = [cv2.contourArea(cont) for cont in img1_contours]\n",
    "img2_contour_areas = [cv2.contourArea(cont) for cont in img2_contours]\n",
    "img3_contour_areas = [cv2.contourArea(cont) for cont in img3_contours]\n",
    "img4_contour_areas = [cv2.contourArea(cont) for cont in img4_contours]\n",
    "\n",
    "img1_idx = np.argmax(img1_contour_areas)\n",
    "img2_idx = np.argmax(img2_contour_areas)\n",
    "img3_idx = np.argmax(img3_contour_areas)\n",
    "img4_idx = np.argmax(img4_contour_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_mask = cv2.drawContours(np.zeros_like(img1_otsu), img1_contours, img1_idx, 255, -1)\n",
    "img2_mask = cv2.drawContours(np.zeros_like(img2_otsu), img2_contours, img2_idx, 255, -1)\n",
    "img3_mask = cv2.drawContours(np.zeros_like(img3_otsu), img3_contours, img3_idx, 255, -1)\n",
    "img4_mask = cv2.drawContours(np.zeros_like(img4_otsu), img4_contours, img4_idx, 255, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment the Breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_seg = cv2.bitwise_and(img1, img1, mask=img1_mask)\n",
    "img2_seg = cv2.bitwise_and(img2, img2, mask=img2_mask)\n",
    "img3_seg = cv2.bitwise_and(img3, img3, mask=img3_mask)\n",
    "img4_seg = cv2.bitwise_and(img4, img4, mask=img4_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, contour):\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    return img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m img1_crop \u001b[38;5;241m=\u001b[39m crop_image(img1_seg, img1_contours[img1_idx])\n\u001b[0;32m----> 2\u001b[0m img2_crop \u001b[38;5;241m=\u001b[39m crop_image(img2_seg, \u001b[43mimg1_contours\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg2_idx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      3\u001b[0m img3_crop \u001b[38;5;241m=\u001b[39m crop_image(img3_seg, img1_contours[img3_idx])\n\u001b[1;32m      4\u001b[0m img4_crop \u001b[38;5;241m=\u001b[39m crop_image(img4_seg, img1_contours[img4_idx])\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "img1_crop = crop_image(img1_seg, img1_contours[img1_idx])\n",
    "img2_crop = crop_image(img2_seg, img2_contours[img2_idx])\n",
    "img3_crop = crop_image(img3_seg, img3_contours[img3_idx])\n",
    "img4_crop = crop_image(img4_seg, img4_contours[img4_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhance Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img1_enhanced = clahe.apply(img1_seg)\n",
    "img2_enhanced = clahe.apply(img2_seg)\n",
    "img3_enhanced = clahe.apply(img3_seg)\n",
    "img4_enhanced = clahe.apply(img4_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suppress_ticks(axes) -> None:\n",
    "    for ax in axes:\n",
    "        _ = ax.set_xticks([])\n",
    "        _ = ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "_ = axes[0].imshow(img1, cmap='gray', aspect='auto')\n",
    "_ = axes[1].imshow(img2, cmap='gray', aspect='auto')\n",
    "_ = axes[2].imshow(img3, cmap='gray', aspect='auto')\n",
    "_ = axes[3].imshow(img4, cmap='gray', aspect='auto')\n",
    "suppress_ticks(axes)\n",
    "fig.suptitle(\"Original Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoised Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "_ = axes[0].imshow(img1_dn, cmap='gray', aspect='auto')\n",
    "_ = axes[1].imshow(img2_dn, cmap='gray', aspect='auto')\n",
    "_ = axes[2].imshow(img3_dn, cmap='gray', aspect='auto')\n",
    "_ = axes[3].imshow(img4_dn, cmap='gray', aspect='auto')\n",
    "suppress_ticks(axes)\n",
    "fig.suptitle(\"Denoised Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "_ = axes[0].imshow(img1_seg, cmap='gray', aspect='auto')\n",
    "_ = axes[1].imshow(img2_seg, cmap='gray', aspect='auto')\n",
    "_ = axes[2].imshow(img3_seg, cmap='gray', aspect='auto')\n",
    "_ = axes[3].imshow(img4_seg, cmap='gray', aspect='auto')\n",
    "suppress_ticks(axes)\n",
    "fig.suptitle(\"Segmented Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "_ = axes[0].imshow(img1_enhanced, cmap='gray', aspect='auto')\n",
    "_ = axes[1].imshow(img2_enhanced, cmap='gray', aspect='auto')\n",
    "_ = axes[2].imshow(img3_enhanced, cmap='gray', aspect='auto')\n",
    "_ = axes[3].imshow(img4_enhanced, cmap='gray', aspect='auto')\n",
    "suppress_ticks(axes)\n",
    "fig.suptitle(\"Enhanced Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "_ = axes[0].imshow(img1_crop, cmap='gray', aspect='auto')\n",
    "_ = axes[1].imshow(img2_crop, cmap='gray', aspect='auto')\n",
    "_ = axes[2].imshow(img3_crop, cmap='gray', aspect='auto')\n",
    "_ = axes[3].imshow(img4_crop, cmap='gray', aspect='auto')\n",
    "suppress_ticks(axes)\n",
    "fig.suptitle(\"Cropped Images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
