{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating Transfer Learning: Gradual fine-tuning of a TensorFlow model produces: “ValueError: Unknown metric function: val_loss.” exception during the fit method of the fine-tuning stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "I’m attempting to automate transfer learning fine-tuning using iterative, gradual thawing of an underlying pre-trained and frozen base network. A compiled model containing the underlying, pre-trained, and frozen base network architecture is fed into an X4Learner class. The class exposes two methods: feature_extraction, and fine_tuning. The feature extraction method fits the model for a designated number of epochs and stores the last epoch as an instance variable. The fine_tuning method operates on the ‘feature_extracted’ model and performs an iterative fine-tuning process in which each iteration thaws some number of layers in the underlying base model, then recompiles it. The next fit step produces the following exception.\n",
    "\n",
    "ValueError: Unknown metric function: val_loss. Please ensure this object is passed to the `custom_objects` argument.\n",
    "\n",
    "The traceback is included at the end of the reproducible example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research\n",
    "Research into potential root causes has been complicated as the exception above has been associated with a host of unrelated problems from missing validation data to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The X4Learner Class Code\n",
    "A simplified version of the transfer learning class follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class X4LearnerLite:\n",
    "    \"\"\"Performs transfer learning of a TensorFlow model containing a pre-trained base model.\n",
    "\n",
    "    Two methods are exposed: extract_features, and fine_tune. The extract_features method trains\n",
    "    the model on the given data using the designated learning rate. The fine_tune method\n",
    "    thaws one or more layers in the model, then trains it on a decayed learning rate. Each\n",
    "    fine tuning session decays the learning rate by a learning_rate_decay factor to mitigate\n",
    "    catastrophic forgetting.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): Model containing a frozen, pre-trained base model.\n",
    "        train_ds (tf.data.Dataset): TensorFlow training dataset.\n",
    "        val_ds (tf.data.Dataset): TensorFlow validation dataset.\n",
    "        base_model_layer (int): Index for the base model layer for thawing.\n",
    "        learning_rate (float): The learning rate for feature extraction. Default = 0.0001\n",
    "        metric (str): The metric used to evaluate model fit performance. Default = 'val_loss'\n",
    "        loss (str): The loss function. Default = 'binary_crossentropy'.\n",
    "        activation (str): Activation function. Default = 'sigmoid'.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: tf.keras.Model,\n",
    "        base_model_layer: int,\n",
    "        train_ds: tf.data.Dataset,\n",
    "        val_ds: tf.data.Dataset,\n",
    "        learning_rate: float = 0.0001,\n",
    "        metric: str = \"val_loss\",\n",
    "        loss: str = \"binary_crossentropy\",\n",
    "        activation: str = \"sigmoid\",\n",
    "    ) -> None:\n",
    "        self._model = model\n",
    "        self._base_model_layer = base_model_layer\n",
    "\n",
    "        self._train_ds = train_ds\n",
    "        self._val_ds = val_ds\n",
    "\n",
    "        self._learning_rate = learning_rate\n",
    "\n",
    "        self._metric = metric\n",
    "        self._loss = loss\n",
    "        self._activation = activation\n",
    "        # Used during the thawing process to determine number of layers to thaw as proportion of\n",
    "        # total number of layers in the underlying base model.\n",
    "        self._n_layers = len(self._model.layers[self._base_model_layer].layers)\n",
    "        self._initial_epoch = None\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------ #\n",
    "    def extract_features(self, epochs: int = 5) -> None:\n",
    "        \"\"\"Performs the feature extraction phase of transfer learning\n",
    "\n",
    "        Args:\n",
    "            epochs (int): Number of epochs to execute\n",
    "        \"\"\"\n",
    "\n",
    "        history = self._model.fit(\n",
    "            self._train_ds,\n",
    "            epochs=epochs,\n",
    "            validation_data=self._val_ds,\n",
    "        )\n",
    "\n",
    "        # Save the last feature extraction epoch for fine tune phase\n",
    "        self._initial_epoch = history.epoch[-1]\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------ #\n",
    "    def fine_tune(\n",
    "        self,\n",
    "        epochs: int = 10,\n",
    "        sessions: int = 10,\n",
    "        learning_rate_decay_factory: float = 0.1,\n",
    "        thaw_rate: Union[float, int] = 0.05,\n",
    "    ) -> None:\n",
    "        \"\"\"Performs iterative fine tuning using gradual unfreezing of the base model.\n",
    "\n",
    "        Args:\n",
    "            epochs (int): Number of epochs per session. Default = 10\n",
    "            sessions (int): Number of fine tuning sessions to execute. Default is 10\n",
    "            learning_rate_decay_factor (float): Factor by which the learning rate is reduced each session.\n",
    "            thaw_rate (Union[float, int]): Rate by which layers are thawed. This can be a raw\n",
    "                integer or a float proportion of base model layers. Default = 0.05.\n",
    "        \"\"\"\n",
    "        session = 0\n",
    "        learning_rate = self._learning_rate\n",
    "        initial_epoch = self._initial_epoch\n",
    "\n",
    "        while session < sessions:\n",
    "            session += 1\n",
    "\n",
    "            learning_rate *= learning_rate_decay_factory\n",
    "\n",
    "            # Thaw the top n layers of the base model according to the following\n",
    "            n = max(int(self._n_layers * thaw_rate * session),1)\n",
    "            self._model.layers[self._base_model_layer].trainable = True\n",
    "            for layer in self._model.layers[self._base_model_layer].layers[:-n]:\n",
    "                layer.trainable = False\n",
    "\n",
    "            self._model.compile(\n",
    "                loss=self._loss,\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                metrics=[self._metric],\n",
    "            )\n",
    "\n",
    "            total_epochs = epochs + initial_epoch\n",
    "            history = self._model.fit(\n",
    "                self._train_ds,\n",
    "                epochs=total_epochs,\n",
    "                validation_data=self._val_ds,\n",
    "                initial_epoch=initial_epoch,\n",
    "            )\n",
    "\n",
    "            initial_epoch = history.epochs[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducible Example\n",
    "This reproducible example borrows liberally from the [TensorFlow transfer learning and fine-tuning tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "#### Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE)\n",
    "\n",
    "# Create a preprocessing layer for the Mobilenet architecture.\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Dataset for Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "#### Create Base Model from MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze the Convolutional Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Task-Specific Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a classification heard\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# Add Dense layer to convert features into single prediction per image.\n",
    "prediction_layer = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0, name='val_loss')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4l = X4LearnerLite(model=model, \n",
    "                    base_model_layer=3, \n",
    "                    train_ds=train_dataset, \n",
    "                    val_ds=validation_dataset, \n",
    "                    learning_rate=0.0001, \n",
    "                    metric=\"val_loss\", \n",
    "                    loss=\"binary_crossentropy\", \n",
    "                    activation=\"signmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 31s 441ms/step - loss: 0.7051 - val_loss: 0.5315 - val_val_loss: 0.7590\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 27s 428ms/step - loss: 0.4682 - val_loss: 0.3646 - val_val_loss: 0.9020\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 26s 416ms/step - loss: 0.3400 - val_loss: 0.2712 - val_val_loss: 0.9370\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 27s 425ms/step - loss: 0.2590 - val_loss: 0.2168 - val_val_loss: 0.9580\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 26s 413ms/step - loss: 0.2159 - val_loss: 0.1809 - val_val_loss: 0.9690\n"
     ]
    }
   ],
   "source": [
    "x4l.extract_features(epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 358, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/metrics.py\", line 4262, in get\n        return deserialize(str(identifier))\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/metrics.py\", line 4218, in deserialize\n        return deserialize_keras_object(\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/utils/generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: val_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx4l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msessions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_decay_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthaw_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 112\u001b[0m, in \u001b[0;36mX4LearnerLite.fine_tune\u001b[0;34m(self, epochs, sessions, learning_rate_decay_factory, thaw_rate)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    106\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss,\n\u001b[1;32m    107\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m    108\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metric],\n\u001b[1;32m    109\u001b[0m )\n\u001b[1;32m    111\u001b[0m total_epochs \u001b[38;5;241m=\u001b[39m epochs \u001b[38;5;241m+\u001b[39m initial_epoch\n\u001b[0;32m--> 112\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_val_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m initial_epoch \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mepochs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/bcd/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 438, in update_state\n        self.build(y_pred, y_true)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 358, in build\n        self._metrics = tf.__internal__.nest.map_structure_up_to(y_pred, self._get_metric_objects,\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 484, in _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 484, in <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 503, in _get_metric_object\n        metric_obj = metrics_mod.get(metric)\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/metrics.py\", line 4262, in get\n        return deserialize(str(identifier))\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/metrics.py\", line 4218, in deserialize\n        return deserialize_keras_object(\n    File \"/home/john/anaconda3/envs/bcd/lib/python3.10/site-packages/keras/utils/generic_utils.py\", line 709, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown metric function: val_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "x4l.fine_tune(epochs=5, sessions=3, learning_rate_decay_factory=0.1, thaw_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.12\n",
      "IPython version      : 8.14.0\n",
      "\n",
      "tensorflow: 2.8.0\n",
      "keras     : 2.8.0\n",
      "\n",
      "Compiler    : GCC 11.2.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.133.1-microsoft-standard-WSL2\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 24\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -m -p tensorflow,keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
