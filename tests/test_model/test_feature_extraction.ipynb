{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dataclasses import dataclass\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from bcd.model.network.shainnet import ShainNetConfig, ShainNetFactory\n",
    "from bcd.model.repo import ModelRepo\n",
    "from bcd.model.base import DenseNet\n",
    "from bcd.model.experiment import Experiment\n",
    "\n",
    "pd.set_option('display.max_rows',999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Parameters\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"test_feature_extraction.ipynb\"\n",
    "datasets = {\"Development\":{\"name\": \"CBIS-DDSM_10\",\"directory\": \"data/image/1_final/training_10/training/\"},\n",
    "            \"Stage\": {\"name\": \"CBIS-DDSM_30\",\"directory\": \"data/image/1_final/training_30/training/\"},\n",
    "            \"Production\": {\"name\": \"CBIS-DDSM\",\"directory\": \"data/image/1_final/training/training/\"},\n",
    "            }\n",
    "mode = \"Development\"\n",
    "project = f\"Breast-Cancer-Detection-{mode}\" \n",
    "\n",
    "# Experiment Parameters\n",
    "force = False  # Whether to retrain if the model and config already exists.\n",
    "\n",
    "# Training Config\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "epochs = 5 # Maximum number of epochs to train, subject to any early stopping callback.\n",
    "learning_rate = 1e-4\n",
    "training_config = {\"loss\": loss, \"epochs\": epochs, \"learning_rate\": learning_rate}\n",
    "\n",
    "# Network Config\n",
    "activation = \"sigmoid\" # Network configuration common to all networks.\n",
    "    \n",
    "# Dataset params\n",
    "dataset = datasets[mode][\"name\"]\n",
    "batch_size = 64 if mode == \"Production\" else 32\n",
    "input_shape = (224,224,3)\n",
    "output_shape = 1\n",
    "train_dir = pathlib.Path(datasets[mode][\"directory\"]).with_suffix('') \n",
    "dataset_config = {\"dataset\": dataset, \"batch_size\": batch_size, \"input_shape\": input_shape, \"output_shape\": output_shape}\n",
    "\n",
    "# Checkpoint Config\n",
    "ckpt_monitor = \"val_accuracy\"\n",
    "ckpt_verbose = 1\n",
    "ckpt_save_best_only = True\n",
    "ckpt_save_weights_only = False\n",
    "ckpt_mode = \"auto\"\n",
    "checkpoint_config = {\"monitor\": ckpt_monitor, \"verbose\": ckpt_verbose, \"save_best_only\": ckpt_save_best_only, \"mode\": ckpt_mode, \"save_weights_only\": ckpt_save_weights_only}\n",
    "\n",
    "# Early stop parameters \n",
    "es_min_delta = 0.0001\n",
    "es_monitor = \"val_loss\"  # Monitor validation loss for early stopping\n",
    "es_patience = 10  # The number of epochs for which lack of improvement is tolerated \n",
    "es_restore_best_weights = True  # Returns the best weights rather than the weights at the last epoch.\n",
    "es_verbose = 1\n",
    "early_stop_config = {\"min_delta\": es_min_delta, \"monitor\": es_monitor, \"patience\": es_patience, \n",
    "                     \"restore_best_weights\": es_restore_best_weights, \"verbose\": es_verbose}\n",
    "\n",
    "# Reduce LR on Plateau Parameters\n",
    "rlr_monitor = \"val_loss\"\n",
    "rlr_factor = 0.5\n",
    "rlr_patience = 3\n",
    "rlr_verbose = 1\n",
    "rlr_mode = \"auto\"\n",
    "rlr_min_delta = 1e-4\n",
    "rlr_min_lr=1e-10\n",
    "learning_rate_schedule_config = {\"monitor\": rlr_monitor, \"factor\": rlr_factor, \"patience\": rlr_patience, \"verbose\": \n",
    "                        rlr_verbose, \"mode\": rlr_mode, \"min_delta\": rlr_min_delta, \"min_lr\": rlr_min_lr}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"project\": project,       \n",
    "    \"mode\": mode,\n",
    "    \"dataset\": dataset_config,\n",
    "    \"training\": training_config,\n",
    "    \"checkpoint\": checkpoint_config,\n",
    "    \"early_stop\": early_stop_config,\n",
    "    \"learning_rate_schedule\": learning_rate_schedule_config,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DataSet \n",
    "train_dir = pathlib.Path(train_dir).with_suffix('') \n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation=\"bilinear\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Validation DataSet (10%)\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(224,224),\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    interpolation=\"bilinear\",\n",
    "    seed=123,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor=es_monitor, \n",
    "                                                       min_delta=es_min_delta,\n",
    "                                                       patience=es_patience, \n",
    "                                                       restore_best_weights=es_restore_best_weights,\n",
    "                                                       verbose=es_verbose)\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor=rlr_monitor,\n",
    "                                                          factor=rlr_factor,\n",
    "                                                          patience=rlr_patience,\n",
    "                                                          verbose=rlr_verbose,\n",
    "                                                          mode=rlr_mode,\n",
    "                                                          min_delta=rlr_min_delta,\n",
    "                                                          min_lr=rlr_min_lr)\n",
    "callbacks = [early_stop_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = ModelRepo(mode = mode, project=project)\n",
    "optimizer=tf.keras.optimizers.Adam\n",
    "metrics = ['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_config = ShainNetConfig(activation=activation)\n",
    "factory = ShainNetFactory(config=network_config, input_shape=input_shape, output_shape=output_shape, activation=activation)\n",
    "network = factory.create(base_model=DenseNet())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(network=network, config=config, optimizer=optimizer, repo=repo, callbacks=callbacks, metrics=metrics, force=force)\n",
    "experiment.run(train_ds=train_ds, val_ds=val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert repo.exists(name=\"ShainNet_DenseNet\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
